{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 14:47:11.487111: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package punkt to /Users/koechian/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import ngrams\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "# Transformers and related libraries\n",
    "import transformers\n",
    "from transformers import pipeline, AutoTokenizer, AutoModel\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2672c1ad",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "- The official ESCO dataset was used as a framework for skill labelling. This ensured consistency in skill labelling and removed any overlapping fields.\n",
    "- A dataset that contained sentences that appear in job descriptions that were labellled with accompanying skills was also used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56d173e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Indeed Dataset has 24714 rows and two cols\n"
     ]
    }
   ],
   "source": [
    "# jobs_train_df = pd.read_csv('../datasets/indeed-dataset.csv')\n",
    "# jobs_test_df = pd.read_csv('../datasets/tech_validation_annotations.csv')\n",
    "# jobs_df = pd.concat([jobs_train_df, jobs_test_df])\n",
    "# jobs_df = jobs_df[['sentence','label']]\n",
    "\n",
    "jobs_df = pd.read_csv('../datasets/indeed-dataset.csv')\n",
    "jobs_df.drop_duplicates(subset=['Job Description'], keep='first', inplace=True)\n",
    "\n",
    "\n",
    "print(f'The Indeed Dataset has {jobs_df.shape[0]} rows and two cols')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2782bbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Location</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Address</th>\n",
       "      <th>...</th>\n",
       "      <th>Employer Phone</th>\n",
       "      <th>Employer Logo</th>\n",
       "      <th>Companydescription</th>\n",
       "      <th>Employer Location</th>\n",
       "      <th>Employer City</th>\n",
       "      <th>Employer State</th>\n",
       "      <th>Employer Country</th>\n",
       "      <th>Employer Zip Code</th>\n",
       "      <th>Uniq Id</th>\n",
       "      <th>Crawl Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shift Manager</td>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mission Hills, CA 91345</td>\n",
       "      <td>Mission Hills</td>\n",
       "      <td>CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>91345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://d2q79iu7y748jz.cloudfront.net/s/_squar...</td>\n",
       "      <td>Del Taco is an American quick service restaura...</td>\n",
       "      <td>Mission Hills, CA 91345</td>\n",
       "      <td>Mission Hills</td>\n",
       "      <td>CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>91345</td>\n",
       "      <td>511f9a53920f4641d701d51d3589349f</td>\n",
       "      <td>2019-08-24 09:13:18 +0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Operations Support Manager</td>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlanta, GA 30342</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>United States</td>\n",
       "      <td>30342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://d2q79iu7y748jz.cloudfront.net/s/_logo/...</td>\n",
       "      <td>Based in Atlanta, FOCUS Brands Inc. is an inno...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4955daf0a3facbe2acb6c429ba394e6d</td>\n",
       "      <td>2019-09-19 08:16:55 +0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Product Manager - Data</td>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vibes Corp. reputation was built and establish...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a0e0d12df1571962b785f17f43ceae12</td>\n",
       "      <td>2019-09-18 02:13:10 +0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Part-Time Office Concierge</td>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Festus, MO</td>\n",
       "      <td>Festus</td>\n",
       "      <td>MO</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56e411fd731f76ac916bf4fb169250e9</td>\n",
       "      <td>2019-10-24 16:39:13 +0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Print &amp; Marketing Associate</td>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cedar Rapids, IA 52404</td>\n",
       "      <td>Cedar Rapids</td>\n",
       "      <td>IA</td>\n",
       "      <td>United States</td>\n",
       "      <td>52404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://d2q79iu7y748jz.cloudfront.net/s/_logo/...</td>\n",
       "      <td>Staples is The Worklife Fulfillment Company, h...</td>\n",
       "      <td>Cedar Rapids, IA 52404</td>\n",
       "      <td>Cedar Rapids</td>\n",
       "      <td>IA</td>\n",
       "      <td>United States</td>\n",
       "      <td>52404</td>\n",
       "      <td>3fff5c0ad6981bf4bff6260bd5feab63</td>\n",
       "      <td>2019-08-24 22:29:10 +0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cyber IT Risk &amp; Strategy Senior Consultant</td>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Washington, DC 20003</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>United States</td>\n",
       "      <td>20003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://d2q79iu7y748jz.cloudfront.net/s/_logo/...</td>\n",
       "      <td>Think a career in professional services is not...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3fcf91a3e406f0727fe30ee09e7910bf</td>\n",
       "      <td>2019-10-18 01:09:20 +0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sales Associate, Retail Part Time</td>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastanollee, GA 30538</td>\n",
       "      <td>Eastanollee</td>\n",
       "      <td>GA</td>\n",
       "      <td>United States</td>\n",
       "      <td>30538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://d2q79iu7y748jz.cloudfront.net/s/_logo/...</td>\n",
       "      <td>GNC has been a leading source of health and we...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9e23f19b5e9502a49ba97fd2e5b78906</td>\n",
       "      <td>2019-09-25 23:49:18 +0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Home Lending Branch Manager-Spokane</td>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spokane, WA 99201</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>WA</td>\n",
       "      <td>United States</td>\n",
       "      <td>99201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://d2q79iu7y748jz.cloudfront.net/s/_logo/...</td>\n",
       "      <td>Today we have over 300 locations across the We...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f570dac5fa316794e7460d6307c0be86</td>\n",
       "      <td>2019-10-24 12:23:37 +0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Property Manager in Training (MIT)</td>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Durham, NC</td>\n",
       "      <td>Durham</td>\n",
       "      <td>NC</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219550967b49d887ac6574d63b001d1b</td>\n",
       "      <td>2019-09-23 09:52:15 +0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Compliance Specialist, Marketing, Advertising ...</td>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de5578ef740fbf9c6a65201bc5877306</td>\n",
       "      <td>2019-10-22 22:30:03 +0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                                      Shift Manager   \n",
       "1                         Operations Support Manager   \n",
       "2                      Senior Product Manager - Data   \n",
       "3                         Part-Time Office Concierge   \n",
       "4                        Print & Marketing Associate   \n",
       "5         Cyber IT Risk & Strategy Senior Consultant   \n",
       "6                  Sales Associate, Retail Part Time   \n",
       "7                Home Lending Branch Manager-Spokane   \n",
       "8                 Property Manager in Training (MIT)   \n",
       "9  Compliance Specialist, Marketing, Advertising ...   \n",
       "\n",
       "                                     Job Description  Job Type  Categories  \\\n",
       "0  <div id=\"jobDescriptionText\" class=\"jobsearch-...       NaN         NaN   \n",
       "1  <div id=\"jobDescriptionText\" class=\"jobsearch-...       NaN         NaN   \n",
       "2  <div id=\"jobDescriptionText\" class=\"jobsearch-...       NaN         NaN   \n",
       "3  <div id=\"jobDescriptionText\" class=\"jobsearch-...       NaN         NaN   \n",
       "4  <div id=\"jobDescriptionText\" class=\"jobsearch-...       NaN         NaN   \n",
       "5  <div id=\"jobDescriptionText\" class=\"jobsearch-...       NaN         NaN   \n",
       "6  <div id=\"jobDescriptionText\" class=\"jobsearch-...       NaN         NaN   \n",
       "7  <div id=\"jobDescriptionText\" class=\"jobsearch-...       NaN         NaN   \n",
       "8  <div id=\"jobDescriptionText\" class=\"jobsearch-...       NaN         NaN   \n",
       "9  <div id=\"jobDescriptionText\" class=\"jobsearch-...       NaN         NaN   \n",
       "\n",
       "                  Location           City State        Country Zip Code  \\\n",
       "0  Mission Hills, CA 91345  Mission Hills    CA  United States    91345   \n",
       "1        Atlanta, GA 30342        Atlanta    GA  United States    30342   \n",
       "2              Chicago, IL        Chicago    IL  United States      NaN   \n",
       "3               Festus, MO         Festus    MO  United States      NaN   \n",
       "4   Cedar Rapids, IA 52404   Cedar Rapids    IA  United States    52404   \n",
       "5     Washington, DC 20003     Washington    DC  United States    20003   \n",
       "6    Eastanollee, GA 30538    Eastanollee    GA  United States    30538   \n",
       "7        Spokane, WA 99201        Spokane    WA  United States    99201   \n",
       "8               Durham, NC         Durham    NC  United States      NaN   \n",
       "9              Chicago, IL        Chicago    IL  United States      NaN   \n",
       "\n",
       "   Address  ...  Employer Phone  \\\n",
       "0      NaN  ...             NaN   \n",
       "1      NaN  ...             NaN   \n",
       "2      NaN  ...             NaN   \n",
       "3      NaN  ...             NaN   \n",
       "4      NaN  ...             NaN   \n",
       "5      NaN  ...             NaN   \n",
       "6      NaN  ...             NaN   \n",
       "7      NaN  ...             NaN   \n",
       "8      NaN  ...             NaN   \n",
       "9      NaN  ...             NaN   \n",
       "\n",
       "                                       Employer Logo  \\\n",
       "0  https://d2q79iu7y748jz.cloudfront.net/s/_squar...   \n",
       "1  https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
       "5  https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
       "6  https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
       "7  https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
       "8                                                NaN   \n",
       "9                                                NaN   \n",
       "\n",
       "                                  Companydescription        Employer Location  \\\n",
       "0  Del Taco is an American quick service restaura...  Mission Hills, CA 91345   \n",
       "1  Based in Atlanta, FOCUS Brands Inc. is an inno...                      NaN   \n",
       "2  Vibes Corp. reputation was built and establish...                      NaN   \n",
       "3                                                NaN                      NaN   \n",
       "4  Staples is The Worklife Fulfillment Company, h...   Cedar Rapids, IA 52404   \n",
       "5  Think a career in professional services is not...                      NaN   \n",
       "6  GNC has been a leading source of health and we...                      NaN   \n",
       "7  Today we have over 300 locations across the We...                      NaN   \n",
       "8                                                NaN                      NaN   \n",
       "9                                                NaN                      NaN   \n",
       "\n",
       "   Employer City  Employer State  Employer Country Employer Zip Code  \\\n",
       "0  Mission Hills              CA     United States             91345   \n",
       "1            NaN             NaN     United States               NaN   \n",
       "2            NaN             NaN     United States               NaN   \n",
       "3            NaN             NaN     United States               NaN   \n",
       "4   Cedar Rapids              IA     United States             52404   \n",
       "5            NaN             NaN     United States               NaN   \n",
       "6            NaN             NaN     United States               NaN   \n",
       "7            NaN             NaN     United States               NaN   \n",
       "8            NaN             NaN     United States               NaN   \n",
       "9            NaN             NaN     United States               NaN   \n",
       "\n",
       "                            Uniq Id            Crawl Timestamp  \n",
       "0  511f9a53920f4641d701d51d3589349f  2019-08-24 09:13:18 +0000  \n",
       "1  4955daf0a3facbe2acb6c429ba394e6d  2019-09-19 08:16:55 +0000  \n",
       "2  a0e0d12df1571962b785f17f43ceae12  2019-09-18 02:13:10 +0000  \n",
       "3  56e411fd731f76ac916bf4fb169250e9  2019-10-24 16:39:13 +0000  \n",
       "4  3fff5c0ad6981bf4bff6260bd5feab63  2019-08-24 22:29:10 +0000  \n",
       "5  3fcf91a3e406f0727fe30ee09e7910bf  2019-10-18 01:09:20 +0000  \n",
       "6  9e23f19b5e9502a49ba97fd2e5b78906  2019-09-25 23:49:18 +0000  \n",
       "7  f570dac5fa316794e7460d6307c0be86  2019-10-24 12:23:37 +0000  \n",
       "8  219550967b49d887ac6574d63b001d1b  2019-09-23 09:52:15 +0000  \n",
       "9  de5578ef740fbf9c6a65201bc5877306  2019-10-22 22:30:03 +0000  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3387af74",
   "metadata": {},
   "source": [
    "### Load and Prep the Esco Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66e4079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "esco_skills = pd.read_csv('../datasets/skills_en.csv')\n",
    "\n",
    "# Remove \"(text)\" occurences\n",
    "esco_skills['label_cleaned'] = esco_skills['preferredLabel'].apply(lambda x: re.sub(r'\\([^)]*\\)', '', x).strip())\n",
    "\n",
    "# Count words in skills after cleaning\n",
    "esco_skills['word_cnt'] = esco_skills['label_cleaned'].apply(lambda x: len(str(x).split()))\n",
    "esco_df = pd.DataFrame(esco_skills, columns=['label_cleaned', 'altLabels', 'word_cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b556cb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EscoDataset(Dataset):\n",
    "    def __init__(self, df, skill_col, backbone):\n",
    "        texts = df\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(backbone)\n",
    "        self.texts = texts[skill_col].values.tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        res = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=20\n",
    "        )\n",
    "        return {k:v[0] for k,v in res.items()}\n",
    "\n",
    "    \n",
    "class ClsPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # batch * num_tokens * num_embedding\n",
    "        return x[:, 0, :]    \n",
    "\n",
    "    \n",
    "class BertModel(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone_name = backbone\n",
    "        self.backbone = AutoModel.from_pretrained(backbone)\n",
    "        self.pool = ClsPool()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(**x)[\"last_hidden_state\"]\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8a2d08",
   "metadata": {},
   "source": [
    "### Loading the BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6632781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at jjzha/jobbert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at jjzha/jobbert-base-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "backbone = 'jjzha/jobbert-base-cased'\n",
    "emb_label = 'jobbert'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset and Dataloader\n",
    "ds = EscoDataset(esco_df, 'label_cleaned', backbone)\n",
    "dl = DataLoader(ds, shuffle=False, batch_size=32)\n",
    "\n",
    "# Build custom model\n",
    "model = BertModel(backbone)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# Get embeddings for each skill\n",
    "embs = []\n",
    "with torch.no_grad():\n",
    "    for i, x in enumerate(dl):\n",
    "        x = {k:v.to(device) for k, v in x.items()}\n",
    "        out = model(x)\n",
    "        embs.extend(out.detach().cpu())\n",
    "# Add them to the DataFrame\n",
    "esco_df[emb_label] = embs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4402f511",
   "metadata": {},
   "source": [
    "1. Get Sentences -> Parses a HTML JD into sentences\n",
    "2. Compute Simmilarity -> Returns the simmilarity between ESCO skills and the provided vector and returns the one with the most simmilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d54df4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(job):\n",
    "    \"\"\"\n",
    "    Given a raw html job description, parse it into sentences\n",
    "    by using nltk's sentence tokenization + new line splitting\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(job, 'html.parser')\n",
    "    # Found some ads using unicode bullet points\n",
    "    for p in soup.find_all('p'):\n",
    "        p.string = p.get_text().replace(\"•\", \"\")\n",
    "    text = soup.get_text()\n",
    "    st = sent_tokenize(text)\n",
    "    sentences = []\n",
    "    for sent in st:\n",
    "        sentences.extend([x for x in sent.split('\\n') if x !=''])\n",
    "    return sentences\n",
    "\n",
    "def compute_similarity(vec, emb_type):\n",
    "    \"\"\"\n",
    "    Compute vector similarity for a given vec and all the ESCO skills embeddings.\n",
    "    If more embeddings were created, the type is specified by the input parameter.\n",
    "    Return the ESCO skill id with max similarity\n",
    "    \"\"\"\n",
    "    esco_embs = esco_df[emb_type]\n",
    "    sims = []\n",
    "    # Compute cosine similarities\n",
    "    for i, esco_vec in enumerate(esco_embs):\n",
    "        sims.append((i, cosine_similarity(vec, esco_vec.reshape(1, -1))))\n",
    "    # Return max similarity and esco skill index\n",
    "    idx, sim = max(sims, key=lambda x: x[1])\n",
    "    return idx, sim.item()\n",
    "\n",
    "\n",
    "def compute_similarity_opt(emb_vec, emb_type):\n",
    "    \"\"\"\n",
    "    Compute vector similarity for a given vec and all the ESCO skills embeddings\n",
    "    by constructing a matrix from ESCO embeddings to process it faster.\n",
    "    Return the ESCO skill id with max similarity\n",
    "    \"\"\"\n",
    "    esco_embs = [x for x in esco_df[emb_type]]\n",
    "    esco_vectors = torch.stack(esco_embs)\n",
    "    # Normalize the stacked embeddings and the input vector\n",
    "    norm_esco_vectors = torch.nn.functional.normalize(esco_vectors, p=2, dim=1)\n",
    "    norm_emb_vec = torch.nn.functional.normalize(emb_vec.T, p=2, dim=0)\n",
    "    # Compute cosine similarities\n",
    "    cos_similarities = torch.matmul(norm_esco_vectors, norm_emb_vec)\n",
    "    # Return max similarity and esco skill index\n",
    "    sim, idx = torch.max(cos_similarities, dim=0)\n",
    "    return idx.item(), sim.item()\n",
    "\n",
    "def compute_similarity_mat(emb_mat, emb_type):\n",
    "    esco_embs = [x for x in esco_df[emb_type]]\n",
    "    esco_vectors = torch.stack(esco_embs)\n",
    "    emb_vectors = torch.stack(emb_mat)\n",
    "    # Normalize the stacked embeddings and the input vectors\n",
    "    norm_esco_vectors = torch.nn.functional.normalize(esco_vectors, p=2, dim=1)\n",
    "    norm_emb_vecs = torch.nn.functional.normalize(emb_vectors.T, p=2, dim=0)\n",
    "    # Compute cosine similarities\n",
    "    cos_similarities = torch.matmul(norm_esco_vectors, norm_emb_vecs)\n",
    "    # Return max similarity and esco skill index\n",
    "    max_similarities, max_indices = torch.max(cos_similarities, dim=0)\n",
    "    return max_indices.numpy(), max_similarities.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a895f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at jjzha/jobbert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at jjzha/jobbert-base-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (backbone): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pool): ClsPool()\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_embedding(x):\n",
    "    x = tokenizer(x, return_tensors='pt')\n",
    "    x = {k:v.to(device) for k, v in x.items()}\n",
    "    return model(x).detach().cpu()\n",
    "\n",
    "def process_sentence(sent):\n",
    "    emb = get_embedding(sent)\n",
    "    return compute_similarity_opt(emb, emb_label)\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(backbone)\n",
    "model = BertModel(backbone)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78ae7bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used in performance optimization and output example\n",
    "job_sample = jobs_df.iloc[30]['Job Description']\n",
    "threshold = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6eca84bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Would you like to be part of a team focused on increasing adoption of Mobile Labs solutions by developing strategic accounts with the Fortune 1000?', 'Mobile Labs employees help our customers solve the chaos of developing and testing multiple apps across multiple platforms, operating systems and device types by providing a private device cloud, either on premise or hosted.', 'Our enterprise direct sales team is focused specifically on large companies.', 'Therefore, our sale people need to possess the skills and experience required to sell into complex processes and organizations.', 'In addition, Mobile Labs is helping customers all over the world achieve their strategic digital transformation goals.', 'Being able to align our solution to these outcomes is also critical to success.', 'A key to our success is our focus on helping our customers win.', 'It is core to our culture & sales methodology.', 'We need great people to help us grow and develop.', 'If the below description sounds like you… please contact us.', 'General Characteristics that will determine your fit for this role:', 'Driven- you set goals and don’t give up till you accomplish them', 'Competitive- You love to win & hate to lose, you don’t take ‘No’ for an answer', 'Continuous learning- Always looking to improve, always building off of your previous accomplishments', 'Intent- Your focus is to help your customers succeed and this intent comes through in all you do', 'Requirements:', 'Bachelor’s degree.', '8+ years of experience in Direct Enterprise software sales with some SaaS experience', 'Proven top performer (consistently overachieves quota)', 'Experience selling directly into complex enterprise processes', 'Have adopted a sales process that guides your thinking and day-to-day activities', 'Create & articulate compelling value proposition around Mobile Labs solutions', 'Work with Partners to extend reach & drive adoption', 'Experience building new territories from scratch', 'Ability to learn complex systems and processes', 'A flexible schedule that can accommodate the requirements of a salesperson in the field.', 'Travel, quarter end etc.', 'Understanding of the Software Development Life Cycle (SDLC), DevOps or Agile Development practices', 'Must have strong verbal and written communication skills.']\n"
     ]
    }
   ],
   "source": [
    "sentences = get_sentences(job_sample)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "599ffeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 2.7882 seconds\n",
      "=========================\n",
      "sentence: Would you like to be part of a team focused on increasing adoption of Mobile Labs solutions by developing strategic accounts with the Fortune 1000?\n",
      "ESCO skill:work with e-services available to clients\n",
      "Similarity:0.7192\n",
      "=========================\n",
      "sentence: Mobile Labs employees help our customers solve the chaos of developing and testing multiple apps across multiple platforms, operating systems and device types by providing a private device cloud, either on premise or hosted.\n",
      "ESCO skill:implement a virtual private network\n",
      "Similarity:0.7466\n",
      "=========================\n",
      "sentence: Our enterprise direct sales team is focused specifically on large companies.\n",
      "ESCO skill:develop online sales business plan\n",
      "Similarity:0.7476\n",
      "=========================\n",
      "sentence: Therefore, our sale people need to possess the skills and experience required to sell into complex processes and organizations.\n",
      "ESCO skill:demonstrate intercultural competences in hospitality services\n",
      "Similarity:0.6923\n",
      "=========================\n",
      "sentence: In addition, Mobile Labs is helping customers all over the world achieve their strategic digital transformation goals.\n",
      "ESCO skill:solve problems in gambling through digital means\n",
      "Similarity:0.7099\n",
      "=========================\n",
      "sentence: Being able to align our solution to these outcomes is also critical to success.\n",
      "ESCO skill:show an exemplary leading role in an organisation\n",
      "Similarity:0.7664\n",
      "=========================\n",
      "sentence: A key to our success is our focus on helping our customers win.\n",
      "ESCO skill:strive to provide high quality customer service\n",
      "Similarity:0.7690\n",
      "=========================\n",
      "sentence: It is core to our culture & sales methodology.\n",
      "ESCO skill:imprint visionary aspirations into the business management\n",
      "Similarity:0.7590\n",
      "=========================\n",
      "sentence: We need great people to help us grow and develop.\n",
      "ESCO skill:create a work environment where performers can develop their potential\n",
      "Similarity:0.7308\n",
      "=========================\n",
      "sentence: If the below description sounds like you… please contact us.\n",
      "ESCO skill:be in touch with your body\n",
      "Similarity:0.7043\n",
      "=========================\n",
      "sentence: General Characteristics that will determine your fit for this role:\n",
      "ESCO skill:match needs of target community with your skills\n",
      "Similarity:0.7024\n",
      "=========================\n",
      "sentence: Driven- you set goals and don’t give up till you accomplish them\n",
      "ESCO skill:think proactively to secure sales\n",
      "Similarity:0.7149\n",
      "=========================\n",
      "sentence: Competitive- You love to win & hate to lose, you don’t take ‘No’ for an answer\n",
      "ESCO skill:manage camelbacks\n",
      "Similarity:0.6831\n",
      "=========================\n",
      "sentence: Continuous learning- Always looking to improve, always building off of your previous accomplishments\n",
      "ESCO skill:record lessons learnt from your sessions\n",
      "Similarity:0.7480\n",
      "=========================\n",
      "sentence: Intent- Your focus is to help your customers succeed and this intent comes through in all you do\n",
      "ESCO skill:strive to provide high quality customer service\n",
      "Similarity:0.7390\n",
      "=========================\n",
      "sentence: Requirements:\n",
      "ESCO skill:check processing parameters\n",
      "Similarity:0.7315\n",
      "=========================\n",
      "sentence: Bachelor’s degree.\n",
      "ESCO skill:player logic\n",
      "Similarity:0.6459\n",
      "=========================\n",
      "sentence: 8+ years of experience in Direct Enterprise software sales with some SaaS experience\n",
      "ESCO skill:SaaS\n",
      "Similarity:0.7420\n",
      "=========================\n",
      "sentence: Proven top performer (consistently overachieves quota)\n",
      "ESCO skill:record multi-track sound\n",
      "Similarity:0.7566\n",
      "=========================\n",
      "sentence: Experience selling directly into complex enterprise processes\n",
      "ESCO skill:business model\n",
      "Similarity:0.7186\n",
      "=========================\n",
      "sentence: Have adopted a sales process that guides your thinking and day-to-day activities\n",
      "ESCO skill:familiarise yourself with the work to be remounted\n",
      "Similarity:0.7932\n",
      "=========================\n",
      "sentence: Create & articulate compelling value proposition around Mobile Labs solutions\n",
      "ESCO skill:plan marketing strategy\n",
      "Similarity:0.7233\n",
      "=========================\n",
      "sentence: Work with Partners to extend reach & drive adoption\n",
      "ESCO skill:identify opportunities\n",
      "Similarity:0.7241\n",
      "=========================\n",
      "sentence: Experience building new territories from scratch\n",
      "ESCO skill:find your place within the architecture of the production\n",
      "Similarity:0.6899\n",
      "=========================\n",
      "sentence: Ability to learn complex systems and processes\n",
      "ESCO skill:use agricultural information systems and databases\n",
      "Similarity:0.7261\n",
      "=========================\n",
      "sentence: A flexible schedule that can accommodate the requirements of a salesperson in the field.\n",
      "ESCO skill:search for a suitable location\n",
      "Similarity:0.7589\n",
      "=========================\n",
      "sentence: Travel, quarter end etc.\n",
      "ESCO skill:control of expenses\n",
      "Similarity:0.7444\n",
      "=========================\n",
      "sentence: Understanding of the Software Development Life Cycle (SDLC), DevOps or Agile Development practices\n",
      "ESCO skill:Agile development\n",
      "Similarity:0.8232\n",
      "=========================\n",
      "sentence: Must have strong verbal and written communication skills.\n",
      "ESCO skill:apply technical communication skills\n",
      "Similarity:0.8219\n"
     ]
    }
   ],
   "source": [
    "sim_start_time = time.time()\n",
    "res = []\n",
    "sentences = get_sentences(job_sample)\n",
    "for sent in sentences:\n",
    "    idx, sim = process_sentence(sent)\n",
    "    if sim > threshold:\n",
    "        res.append((sent, esco_df.iloc[idx]['label_cleaned'], sim))\n",
    "\n",
    "sim_end_time = time.time()\n",
    "execution_time = sim_end_time - sim_start_time\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "\n",
    "for r in res:\n",
    "    print('=========================')\n",
    "    print(f\"sentence: {r[0]}\\nESCO skill:{r[1]}\\nSimilarity:{r[2]:.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d31e1509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 1.2839 seconds\n",
      "=========================\n",
      "sentence: Would you like to be part of a team focused on increasing adoption of Mobile Labs solutions by developing strategic accounts with the Fortune 1000?\n",
      "ESCO skill:work with e-services available to clients\n",
      "Similarity:0.7192\n",
      "=========================\n",
      "sentence: Mobile Labs employees help our customers solve the chaos of developing and testing multiple apps across multiple platforms, operating systems and device types by providing a private device cloud, either on premise or hosted.\n",
      "ESCO skill:implement a virtual private network\n",
      "Similarity:0.7466\n",
      "=========================\n",
      "sentence: Our enterprise direct sales team is focused specifically on large companies.\n",
      "ESCO skill:develop online sales business plan\n",
      "Similarity:0.7476\n",
      "=========================\n",
      "sentence: Therefore, our sale people need to possess the skills and experience required to sell into complex processes and organizations.\n",
      "ESCO skill:demonstrate intercultural competences in hospitality services\n",
      "Similarity:0.6923\n",
      "=========================\n",
      "sentence: In addition, Mobile Labs is helping customers all over the world achieve their strategic digital transformation goals.\n",
      "ESCO skill:solve problems in gambling through digital means\n",
      "Similarity:0.7099\n",
      "=========================\n",
      "sentence: Being able to align our solution to these outcomes is also critical to success.\n",
      "ESCO skill:show an exemplary leading role in an organisation\n",
      "Similarity:0.7664\n",
      "=========================\n",
      "sentence: A key to our success is our focus on helping our customers win.\n",
      "ESCO skill:strive to provide high quality customer service\n",
      "Similarity:0.7690\n",
      "=========================\n",
      "sentence: It is core to our culture & sales methodology.\n",
      "ESCO skill:imprint visionary aspirations into the business management\n",
      "Similarity:0.7590\n",
      "=========================\n",
      "sentence: We need great people to help us grow and develop.\n",
      "ESCO skill:create a work environment where performers can develop their potential\n",
      "Similarity:0.7308\n",
      "=========================\n",
      "sentence: If the below description sounds like you… please contact us.\n",
      "ESCO skill:be in touch with your body\n",
      "Similarity:0.7043\n",
      "=========================\n",
      "sentence: General Characteristics that will determine your fit for this role:\n",
      "ESCO skill:match needs of target community with your skills\n",
      "Similarity:0.7024\n",
      "=========================\n",
      "sentence: Driven- you set goals and don’t give up till you accomplish them\n",
      "ESCO skill:think proactively to secure sales\n",
      "Similarity:0.7149\n",
      "=========================\n",
      "sentence: Competitive- You love to win & hate to lose, you don’t take ‘No’ for an answer\n",
      "ESCO skill:manage camelbacks\n",
      "Similarity:0.6831\n",
      "=========================\n",
      "sentence: Continuous learning- Always looking to improve, always building off of your previous accomplishments\n",
      "ESCO skill:record lessons learnt from your sessions\n",
      "Similarity:0.7480\n",
      "=========================\n",
      "sentence: Intent- Your focus is to help your customers succeed and this intent comes through in all you do\n",
      "ESCO skill:strive to provide high quality customer service\n",
      "Similarity:0.7390\n",
      "=========================\n",
      "sentence: Requirements:\n",
      "ESCO skill:check processing parameters\n",
      "Similarity:0.7315\n",
      "=========================\n",
      "sentence: Bachelor’s degree.\n",
      "ESCO skill:player logic\n",
      "Similarity:0.6459\n",
      "=========================\n",
      "sentence: 8+ years of experience in Direct Enterprise software sales with some SaaS experience\n",
      "ESCO skill:SaaS\n",
      "Similarity:0.7420\n",
      "=========================\n",
      "sentence: Proven top performer (consistently overachieves quota)\n",
      "ESCO skill:record multi-track sound\n",
      "Similarity:0.7566\n",
      "=========================\n",
      "sentence: Experience selling directly into complex enterprise processes\n",
      "ESCO skill:business model\n",
      "Similarity:0.7186\n",
      "=========================\n",
      "sentence: Have adopted a sales process that guides your thinking and day-to-day activities\n",
      "ESCO skill:familiarise yourself with the work to be remounted\n",
      "Similarity:0.7932\n",
      "=========================\n",
      "sentence: Create & articulate compelling value proposition around Mobile Labs solutions\n",
      "ESCO skill:plan marketing strategy\n",
      "Similarity:0.7233\n",
      "=========================\n",
      "sentence: Work with Partners to extend reach & drive adoption\n",
      "ESCO skill:identify opportunities\n",
      "Similarity:0.7241\n",
      "=========================\n",
      "sentence: Experience building new territories from scratch\n",
      "ESCO skill:find your place within the architecture of the production\n",
      "Similarity:0.6899\n",
      "=========================\n",
      "sentence: Ability to learn complex systems and processes\n",
      "ESCO skill:use agricultural information systems and databases\n",
      "Similarity:0.7261\n",
      "=========================\n",
      "sentence: A flexible schedule that can accommodate the requirements of a salesperson in the field.\n",
      "ESCO skill:search for a suitable location\n",
      "Similarity:0.7589\n",
      "=========================\n",
      "sentence: Travel, quarter end etc.\n",
      "ESCO skill:control of expenses\n",
      "Similarity:0.7444\n",
      "=========================\n",
      "sentence: Understanding of the Software Development Life Cycle (SDLC), DevOps or Agile Development practices\n",
      "ESCO skill:Agile development\n",
      "Similarity:0.8232\n",
      "=========================\n",
      "sentence: Must have strong verbal and written communication skills.\n",
      "ESCO skill:apply technical communication skills\n",
      "Similarity:0.8219\n"
     ]
    }
   ],
   "source": [
    "sentences = get_sentences(job_sample)\n",
    "\n",
    "sim_start_time = time.time()\n",
    "sent_embs = []\n",
    "\n",
    "for sent in sentences:\n",
    "    x = tokenizer(sent, return_tensors='pt')\n",
    "    x = {k:v.to(device) for k, v in x.items()}\n",
    "    emb = model(x).detach().cpu()\n",
    "    sent_embs.append(emb.squeeze())\n",
    "idxs, sims = compute_similarity_mat(sent_embs, emb_label)\n",
    "# Calculate job description processing time\n",
    "sim_end_time = time.time()\n",
    "execution_time = sim_end_time - sim_start_time\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "\n",
    "for r in res:\n",
    "    print('=========================')\n",
    "    print(f\"sentence: {r[0]}\\nESCO skill:{r[1]}\\nSimilarity:{r[2]:.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75ad5459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifiers(mtype):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    if mtype == \"jobbert\":\n",
    "        token_skill_classifier = pipeline(model=\"jjzha/jobbert_skill_extraction\", aggregation_strategy=\"first\", device='cpu')\n",
    "        token_knowledge_classifier = pipeline(model=\"jjzha/jobbert_knowledge_extraction\", aggregation_strategy=\"first\", device=device)\n",
    "    elif mtype == \"xlmr\":        \n",
    "        token_skill_classifier = pipeline(model=\"jjzha/escoxlmr_skill_extraction\", aggregation_strategy=\"first\", device=device)\n",
    "        token_knowledge_classifier = pipeline(model=\"jjzha/escoxlmr_knowledge_extraction\", aggregation_strategy=\"first\", device=device)\n",
    "    else:\n",
    "        raise Exception(\"Unknown model name provided\")\n",
    "    return token_skill_classifier, token_knowledge_classifier\n",
    "\n",
    "\n",
    "def extract_skills(job, token_skill_classifier, token_knowledge_classifier, out_treshold=.8, sim_threshold=.8):\n",
    "    \"\"\"\n",
    "    Function that processes outputs from pre-trained, ready to use models\n",
    "    that detect skills as a token classification task. There are two thresholds,\n",
    "    out_threshold for filtering model outputs and sim_threshold for filtering\n",
    "    based on vector similarity with ESCO skills\n",
    "    \"\"\"     \n",
    "    sentences = get_sentences(job)\n",
    "    pred_labels = []\n",
    "    res = []\n",
    "    skill_embs = []\n",
    "    skill_texts = []\n",
    "    for sent in sentences:\n",
    "        skills = ner(sent, token_skill_classifier, token_knowledge_classifier)\n",
    "        for entity in skills['entities']:\n",
    "            text = entity['word']\n",
    "            if entity['score'] > out_treshold:\n",
    "                skill_embs.append(get_embedding(text).squeeze())\n",
    "                skill_texts.append(text)\n",
    "                \n",
    "    idxs, sims = compute_similarity_mat(skill_embs, emb_label)\n",
    "    for i in range(len(idxs)):\n",
    "        if sims[i] > sim_threshold:\n",
    "            pred_labels.append(idxs[i])\n",
    "            res.append((skill_texts[i], esco_df.iloc[idxs[i]]['label_cleaned'], sims[i]))\n",
    "    return pred_labels, res\n",
    "\n",
    "\n",
    "def aggregate_span(results):\n",
    "    new_results = []\n",
    "    current_result = results[0]\n",
    "\n",
    "    for result in results[1:]:\n",
    "        if result[\"start\"] == current_result[\"end\"] + 1:\n",
    "            current_result[\"word\"] += \" \" + result[\"word\"]\n",
    "            current_result[\"end\"] = result[\"end\"]\n",
    "        else:\n",
    "            new_results.append(current_result)\n",
    "            current_result = result\n",
    "\n",
    "    new_results.append(current_result)\n",
    "\n",
    "    return new_results\n",
    "\n",
    "\n",
    "def ner(text, token_skill_classifier, token_knowledge_classifier):\n",
    "    output_skills = token_skill_classifier(text)\n",
    "    for result in output_skills:\n",
    "        if result.get(\"entity_group\"):\n",
    "            result[\"entity\"] = \"Skill\"\n",
    "            del result[\"entity_group\"]\n",
    "\n",
    "    output_knowledge = token_knowledge_classifier(text)\n",
    "    for result in output_knowledge:\n",
    "        if result.get(\"entity_group\"):\n",
    "            result[\"entity\"] = \"Knowledge\"\n",
    "            del result[\"entity_group\"]\n",
    "\n",
    "    if len(output_skills) > 0:\n",
    "        output_skills = aggregate_span(output_skills)\n",
    "    if len(output_knowledge) > 0:\n",
    "        output_knowledge = aggregate_span(output_knowledge)\n",
    "    \n",
    "    skills = []\n",
    "    skills.extend(output_skills)\n",
    "    skills.extend(output_knowledge)\n",
    "    return {\"text\": text, \"entities\": skills}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20530981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c964be68a50746e2b5fbab01d418530a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tsc, tkc \u001b[38;5;241m=\u001b[39m \u001b[43mget_classifiers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjobbert\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      4\u001b[0m _, res \u001b[38;5;241m=\u001b[39m extract_skills(job_sample, tsc, tkc)\n",
      "Cell \u001b[0;32mIn[54], line 4\u001b[0m, in \u001b[0;36mget_classifiers\u001b[0;34m(mtype)\u001b[0m\n\u001b[1;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjobbert\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 4\u001b[0m     token_skill_classifier \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjjzha/jobbert_skill_extraction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggregation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfirst\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     token_knowledge_classifier \u001b[38;5;241m=\u001b[39m pipeline(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjjzha/jobbert_knowledge_extraction\u001b[39m\u001b[38;5;124m\"\u001b[39m, aggregation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxlmr\u001b[39m\u001b[38;5;124m\"\u001b[39m:        \n",
      "File \u001b[0;32m~/anaconda3/envs/skillexplore/lib/python3.10/site-packages/transformers/pipelines/__init__.py:651\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_extractor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    649\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_extractor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m feature_extractor\n\u001b[0;32m--> 651\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpipeline_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/skillexplore/lib/python3.10/site-packages/transformers/pipelines/token_classification.py:102\u001b[0m, in \u001b[0;36mTokenClassificationPipeline.__init__\u001b[0;34m(self, args_parser, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, args_parser\u001b[38;5;241m=\u001b[39mTokenClassificationArgumentHandler(), \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_model_type(\n\u001b[1;32m    104\u001b[0m         TF_MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING\n\u001b[1;32m    107\u001b[0m     )\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_basic_tokenizer \u001b[38;5;241m=\u001b[39m BasicTokenizer(do_lower_case\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/skillexplore/lib/python3.10/site-packages/transformers/pipelines/base.py:732\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[0;34m(self, model, tokenizer, feature_extractor, modelcard, framework, task, args_parser, device, binary_output, **kwargs)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodelcard \u001b[38;5;241m=\u001b[39m modelcard\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m=\u001b[39m framework\n\u001b[0;32m--> 732\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary_output \u001b[38;5;241m=\u001b[39m binary_output\n\u001b[1;32m    735\u001b[0m \u001b[38;5;66;03m# Special handling\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "tsc, tkc = get_classifiers(\"jobbert\")\n",
    "\n",
    "start_time = time.time()\n",
    "_, res = extract_skills(job_sample, tsc, tkc)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "for r in res:\n",
    "    print('=========================')\n",
    "    print(f\"text: {r[0]}\\nESCO skill:{r[1]}\\nSimilarity:{r[2]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
