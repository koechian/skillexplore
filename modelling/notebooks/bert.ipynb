{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-06 14:09:52.580949: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package punkt to /Users/koechian/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import ngrams\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "# Transformers and related libraries\n",
    "import transformers\n",
    "from transformers import pipeline, AutoTokenizer, AutoModel\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2672c1ad",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "- Two datasets were used, in one, a sentence is labelled with a skill, in the other, whole job descriptions are labelled with skills "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56d173e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "singaporedf = pd.read_csv('../datasets/singapore-cleaned.csv')\n",
    "sentence_df = pd.read_csv('../datasets/sentence-skill-labelled.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79279d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EscoDataset(Dataset):\n",
    "    def __init__(self, df, skill_col, backbone):\n",
    "        texts = df\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(backbone)\n",
    "        self.texts = texts[skill_col].values.tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        res = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=20\n",
    "        )\n",
    "        return {k:v[0] for k,v in res.items()}\n",
    "\n",
    "    \n",
    "class ClsPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # batch * num_tokens * num_embedding\n",
    "        return x[:, 0, :]    \n",
    "\n",
    "    \n",
    "class BertModel(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone_name = backbone\n",
    "        self.backbone = AutoModel.from_pretrained(backbone)\n",
    "        self.pool = ClsPool()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(**x)[\"last_hidden_state\"]\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8a2d08",
   "metadata": {},
   "source": [
    "### Loading the BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6632781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at jjzha/jobbert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at jjzha/jobbert-base-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "backbone = 'jjzha/jobbert-base-cased'\n",
    "emb_label = 'jobbert'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset and Dataloader\n",
    "ds = EscoDataset(esco_df, 'label_cleaned', backbone)\n",
    "dl = DataLoader(ds, shuffle=False, batch_size=32)\n",
    "# Build custom model\n",
    "model = BertModel(backbone)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# Get embeddings for each skill\n",
    "embs = []\n",
    "with torch.no_grad():\n",
    "    for i, x in enumerate(dl):\n",
    "        x = {k:v.to(device) for k, v in x.items()}\n",
    "        out = model(x)\n",
    "        embs.extend(out.detach().cpu())\n",
    "# Add them to the DataFrame\n",
    "esco_df[emb_label] = embs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4402f511",
   "metadata": {},
   "source": [
    "1. Get Sentences -> Parses a HTML JD into sentences\n",
    "2. Compute Simmilarity -> Returns the simmilarity between ESCO skills and the provided vector and returns the one with the most simmilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d54df4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(job):\n",
    "    \"\"\"\n",
    "    Given a raw html job description, parse it into sentences\n",
    "    by using nltk's sentence tokenization + new line splitting\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(job, 'html.parser')\n",
    "    # Found some ads using unicode bullet points\n",
    "    for p in soup.find_all('p'):\n",
    "        p.string = p.get_text().replace(\"•\", \"\")\n",
    "    text = soup.get_text()\n",
    "    st = sent_tokenize(text)\n",
    "    sentences = []\n",
    "    for sent in st:\n",
    "        sentences.extend([x for x in sent.split('\\n') if x !=''])\n",
    "    return sentences\n",
    "\n",
    "def compute_similarity(vec, emb_type):\n",
    "    \"\"\"\n",
    "    Compute vector similarity for a given vec and all the ESCO skills embeddings.\n",
    "    If more embeddings were created, the type is specified by the input parameter.\n",
    "    Return the ESCO skill id with max similarity\n",
    "    \"\"\"\n",
    "    esco_embs = esco_df[emb_type]\n",
    "    sims = []\n",
    "    # Compute cosine similarities\n",
    "    for i, esco_vec in enumerate(esco_embs):\n",
    "        sims.append((i, cosine_similarity(vec, esco_vec.reshape(1, -1))))\n",
    "    # Return max similarity and esco skill index\n",
    "    idx, sim = max(sims, key=lambda x: x[1])\n",
    "    return idx, sim.item()\n",
    "\n",
    "\n",
    "def compute_similarity_opt(emb_vec, emb_type):\n",
    "    \"\"\"\n",
    "    Compute vector similarity for a given vec and all the ESCO skills embeddings\n",
    "    by constructing a matrix from ESCO embeddings to process it faster.\n",
    "    Return the ESCO skill id with max similarity\n",
    "    \"\"\"\n",
    "    esco_embs = [x for x in esco_df[emb_type]]\n",
    "    esco_vectors = torch.stack(esco_embs)\n",
    "    # Normalize the stacked embeddings and the input vector\n",
    "    norm_esco_vectors = torch.nn.functional.normalize(esco_vectors, p=2, dim=1)\n",
    "    norm_emb_vec = torch.nn.functional.normalize(emb_vec.T, p=2, dim=0)\n",
    "    # Compute cosine similarities\n",
    "    cos_similarities = torch.matmul(norm_esco_vectors, norm_emb_vec)\n",
    "    # Return max similarity and esco skill index\n",
    "    sim, idx = torch.max(cos_similarities, dim=0)\n",
    "    return idx.item(), sim.item()\n",
    "\n",
    "def compute_similarity_mat(emb_mat, emb_type):\n",
    "    esco_embs = [x for x in esco_df[emb_type]]\n",
    "    esco_vectors = torch.stack(esco_embs)\n",
    "    emb_vectors = torch.stack(emb_mat)\n",
    "    # Normalize the stacked embeddings and the input vectors\n",
    "    norm_esco_vectors = torch.nn.functional.normalize(esco_vectors, p=2, dim=1)\n",
    "    norm_emb_vecs = torch.nn.functional.normalize(emb_vectors.T, p=2, dim=0)\n",
    "    # Compute cosine similarities\n",
    "    cos_similarities = torch.matmul(norm_esco_vectors, norm_emb_vecs)\n",
    "    # Return max similarity and esco skill index\n",
    "    max_similarities, max_indices = torch.max(cos_similarities, dim=0)\n",
    "    return max_indices.numpy(), max_similarities.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a895f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at jjzha/jobbert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at jjzha/jobbert-base-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (backbone): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pool): ClsPool()\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_embedding(x):\n",
    "    x = tokenizer(x, return_tensors='pt')\n",
    "    x = {k:v.to(device) for k, v in x.items()}\n",
    "    return model(x).detach().cpu()\n",
    "\n",
    "def process_sentence(sent):\n",
    "    emb = get_embedding(sent)\n",
    "    return compute_similarity_opt(emb, emb_label)\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(backbone)\n",
    "model = BertModel(backbone)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78ae7bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used in performance optimization and output example\n",
    "job_sample = jobs_df.iloc[30]['Job Description']\n",
    "threshold = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6eca84bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Would you like to be part of a team focused on increasing adoption of Mobile Labs solutions by developing strategic accounts with the Fortune 1000?', 'Mobile Labs employees help our customers solve the chaos of developing and testing multiple apps across multiple platforms, operating systems and device types by providing a private device cloud, either on premise or hosted.', 'Our enterprise direct sales team is focused specifically on large companies.', 'Therefore, our sale people need to possess the skills and experience required to sell into complex processes and organizations.', 'In addition, Mobile Labs is helping customers all over the world achieve their strategic digital transformation goals.', 'Being able to align our solution to these outcomes is also critical to success.', 'A key to our success is our focus on helping our customers win.', 'It is core to our culture & sales methodology.', 'We need great people to help us grow and develop.', 'If the below description sounds like you… please contact us.', 'General Characteristics that will determine your fit for this role:', 'Driven- you set goals and don’t give up till you accomplish them', 'Competitive- You love to win & hate to lose, you don’t take ‘No’ for an answer', 'Continuous learning- Always looking to improve, always building off of your previous accomplishments', 'Intent- Your focus is to help your customers succeed and this intent comes through in all you do', 'Requirements:', 'Bachelor’s degree.', '8+ years of experience in Direct Enterprise software sales with some SaaS experience', 'Proven top performer (consistently overachieves quota)', 'Experience selling directly into complex enterprise processes', 'Have adopted a sales process that guides your thinking and day-to-day activities', 'Create & articulate compelling value proposition around Mobile Labs solutions', 'Work with Partners to extend reach & drive adoption', 'Experience building new territories from scratch', 'Ability to learn complex systems and processes', 'A flexible schedule that can accommodate the requirements of a salesperson in the field.', 'Travel, quarter end etc.', 'Understanding of the Software Development Life Cycle (SDLC), DevOps or Agile Development practices', 'Must have strong verbal and written communication skills.']\n"
     ]
    }
   ],
   "source": [
    "sentences = get_sentences(job_sample)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "599ffeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 2.7882 seconds\n",
      "=========================\n",
      "sentence: Would you like to be part of a team focused on increasing adoption of Mobile Labs solutions by developing strategic accounts with the Fortune 1000?\n",
      "ESCO skill:work with e-services available to clients\n",
      "Similarity:0.7192\n",
      "=========================\n",
      "sentence: Mobile Labs employees help our customers solve the chaos of developing and testing multiple apps across multiple platforms, operating systems and device types by providing a private device cloud, either on premise or hosted.\n",
      "ESCO skill:implement a virtual private network\n",
      "Similarity:0.7466\n",
      "=========================\n",
      "sentence: Our enterprise direct sales team is focused specifically on large companies.\n",
      "ESCO skill:develop online sales business plan\n",
      "Similarity:0.7476\n",
      "=========================\n",
      "sentence: Therefore, our sale people need to possess the skills and experience required to sell into complex processes and organizations.\n",
      "ESCO skill:demonstrate intercultural competences in hospitality services\n",
      "Similarity:0.6923\n",
      "=========================\n",
      "sentence: In addition, Mobile Labs is helping customers all over the world achieve their strategic digital transformation goals.\n",
      "ESCO skill:solve problems in gambling through digital means\n",
      "Similarity:0.7099\n",
      "=========================\n",
      "sentence: Being able to align our solution to these outcomes is also critical to success.\n",
      "ESCO skill:show an exemplary leading role in an organisation\n",
      "Similarity:0.7664\n",
      "=========================\n",
      "sentence: A key to our success is our focus on helping our customers win.\n",
      "ESCO skill:strive to provide high quality customer service\n",
      "Similarity:0.7690\n",
      "=========================\n",
      "sentence: It is core to our culture & sales methodology.\n",
      "ESCO skill:imprint visionary aspirations into the business management\n",
      "Similarity:0.7590\n",
      "=========================\n",
      "sentence: We need great people to help us grow and develop.\n",
      "ESCO skill:create a work environment where performers can develop their potential\n",
      "Similarity:0.7308\n",
      "=========================\n",
      "sentence: If the below description sounds like you… please contact us.\n",
      "ESCO skill:be in touch with your body\n",
      "Similarity:0.7043\n",
      "=========================\n",
      "sentence: General Characteristics that will determine your fit for this role:\n",
      "ESCO skill:match needs of target community with your skills\n",
      "Similarity:0.7024\n",
      "=========================\n",
      "sentence: Driven- you set goals and don’t give up till you accomplish them\n",
      "ESCO skill:think proactively to secure sales\n",
      "Similarity:0.7149\n",
      "=========================\n",
      "sentence: Competitive- You love to win & hate to lose, you don’t take ‘No’ for an answer\n",
      "ESCO skill:manage camelbacks\n",
      "Similarity:0.6831\n",
      "=========================\n",
      "sentence: Continuous learning- Always looking to improve, always building off of your previous accomplishments\n",
      "ESCO skill:record lessons learnt from your sessions\n",
      "Similarity:0.7480\n",
      "=========================\n",
      "sentence: Intent- Your focus is to help your customers succeed and this intent comes through in all you do\n",
      "ESCO skill:strive to provide high quality customer service\n",
      "Similarity:0.7390\n",
      "=========================\n",
      "sentence: Requirements:\n",
      "ESCO skill:check processing parameters\n",
      "Similarity:0.7315\n",
      "=========================\n",
      "sentence: Bachelor’s degree.\n",
      "ESCO skill:player logic\n",
      "Similarity:0.6459\n",
      "=========================\n",
      "sentence: 8+ years of experience in Direct Enterprise software sales with some SaaS experience\n",
      "ESCO skill:SaaS\n",
      "Similarity:0.7420\n",
      "=========================\n",
      "sentence: Proven top performer (consistently overachieves quota)\n",
      "ESCO skill:record multi-track sound\n",
      "Similarity:0.7566\n",
      "=========================\n",
      "sentence: Experience selling directly into complex enterprise processes\n",
      "ESCO skill:business model\n",
      "Similarity:0.7186\n",
      "=========================\n",
      "sentence: Have adopted a sales process that guides your thinking and day-to-day activities\n",
      "ESCO skill:familiarise yourself with the work to be remounted\n",
      "Similarity:0.7932\n",
      "=========================\n",
      "sentence: Create & articulate compelling value proposition around Mobile Labs solutions\n",
      "ESCO skill:plan marketing strategy\n",
      "Similarity:0.7233\n",
      "=========================\n",
      "sentence: Work with Partners to extend reach & drive adoption\n",
      "ESCO skill:identify opportunities\n",
      "Similarity:0.7241\n",
      "=========================\n",
      "sentence: Experience building new territories from scratch\n",
      "ESCO skill:find your place within the architecture of the production\n",
      "Similarity:0.6899\n",
      "=========================\n",
      "sentence: Ability to learn complex systems and processes\n",
      "ESCO skill:use agricultural information systems and databases\n",
      "Similarity:0.7261\n",
      "=========================\n",
      "sentence: A flexible schedule that can accommodate the requirements of a salesperson in the field.\n",
      "ESCO skill:search for a suitable location\n",
      "Similarity:0.7589\n",
      "=========================\n",
      "sentence: Travel, quarter end etc.\n",
      "ESCO skill:control of expenses\n",
      "Similarity:0.7444\n",
      "=========================\n",
      "sentence: Understanding of the Software Development Life Cycle (SDLC), DevOps or Agile Development practices\n",
      "ESCO skill:Agile development\n",
      "Similarity:0.8232\n",
      "=========================\n",
      "sentence: Must have strong verbal and written communication skills.\n",
      "ESCO skill:apply technical communication skills\n",
      "Similarity:0.8219\n"
     ]
    }
   ],
   "source": [
    "sim_start_time = time.time()\n",
    "res = []\n",
    "sentences = get_sentences(job_sample)\n",
    "for sent in sentences:\n",
    "    idx, sim = process_sentence(sent)\n",
    "    if sim > threshold:\n",
    "        res.append((sent, esco_df.iloc[idx]['label_cleaned'], sim))\n",
    "\n",
    "sim_end_time = time.time()\n",
    "execution_time = sim_end_time - sim_start_time\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "\n",
    "for r in res:\n",
    "    print('=========================')\n",
    "    print(f\"sentence: {r[0]}\\nESCO skill:{r[1]}\\nSimilarity:{r[2]:.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d31e1509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 1.2839 seconds\n",
      "=========================\n",
      "sentence: Would you like to be part of a team focused on increasing adoption of Mobile Labs solutions by developing strategic accounts with the Fortune 1000?\n",
      "ESCO skill:work with e-services available to clients\n",
      "Similarity:0.7192\n",
      "=========================\n",
      "sentence: Mobile Labs employees help our customers solve the chaos of developing and testing multiple apps across multiple platforms, operating systems and device types by providing a private device cloud, either on premise or hosted.\n",
      "ESCO skill:implement a virtual private network\n",
      "Similarity:0.7466\n",
      "=========================\n",
      "sentence: Our enterprise direct sales team is focused specifically on large companies.\n",
      "ESCO skill:develop online sales business plan\n",
      "Similarity:0.7476\n",
      "=========================\n",
      "sentence: Therefore, our sale people need to possess the skills and experience required to sell into complex processes and organizations.\n",
      "ESCO skill:demonstrate intercultural competences in hospitality services\n",
      "Similarity:0.6923\n",
      "=========================\n",
      "sentence: In addition, Mobile Labs is helping customers all over the world achieve their strategic digital transformation goals.\n",
      "ESCO skill:solve problems in gambling through digital means\n",
      "Similarity:0.7099\n",
      "=========================\n",
      "sentence: Being able to align our solution to these outcomes is also critical to success.\n",
      "ESCO skill:show an exemplary leading role in an organisation\n",
      "Similarity:0.7664\n",
      "=========================\n",
      "sentence: A key to our success is our focus on helping our customers win.\n",
      "ESCO skill:strive to provide high quality customer service\n",
      "Similarity:0.7690\n",
      "=========================\n",
      "sentence: It is core to our culture & sales methodology.\n",
      "ESCO skill:imprint visionary aspirations into the business management\n",
      "Similarity:0.7590\n",
      "=========================\n",
      "sentence: We need great people to help us grow and develop.\n",
      "ESCO skill:create a work environment where performers can develop their potential\n",
      "Similarity:0.7308\n",
      "=========================\n",
      "sentence: If the below description sounds like you… please contact us.\n",
      "ESCO skill:be in touch with your body\n",
      "Similarity:0.7043\n",
      "=========================\n",
      "sentence: General Characteristics that will determine your fit for this role:\n",
      "ESCO skill:match needs of target community with your skills\n",
      "Similarity:0.7024\n",
      "=========================\n",
      "sentence: Driven- you set goals and don’t give up till you accomplish them\n",
      "ESCO skill:think proactively to secure sales\n",
      "Similarity:0.7149\n",
      "=========================\n",
      "sentence: Competitive- You love to win & hate to lose, you don’t take ‘No’ for an answer\n",
      "ESCO skill:manage camelbacks\n",
      "Similarity:0.6831\n",
      "=========================\n",
      "sentence: Continuous learning- Always looking to improve, always building off of your previous accomplishments\n",
      "ESCO skill:record lessons learnt from your sessions\n",
      "Similarity:0.7480\n",
      "=========================\n",
      "sentence: Intent- Your focus is to help your customers succeed and this intent comes through in all you do\n",
      "ESCO skill:strive to provide high quality customer service\n",
      "Similarity:0.7390\n",
      "=========================\n",
      "sentence: Requirements:\n",
      "ESCO skill:check processing parameters\n",
      "Similarity:0.7315\n",
      "=========================\n",
      "sentence: Bachelor’s degree.\n",
      "ESCO skill:player logic\n",
      "Similarity:0.6459\n",
      "=========================\n",
      "sentence: 8+ years of experience in Direct Enterprise software sales with some SaaS experience\n",
      "ESCO skill:SaaS\n",
      "Similarity:0.7420\n",
      "=========================\n",
      "sentence: Proven top performer (consistently overachieves quota)\n",
      "ESCO skill:record multi-track sound\n",
      "Similarity:0.7566\n",
      "=========================\n",
      "sentence: Experience selling directly into complex enterprise processes\n",
      "ESCO skill:business model\n",
      "Similarity:0.7186\n",
      "=========================\n",
      "sentence: Have adopted a sales process that guides your thinking and day-to-day activities\n",
      "ESCO skill:familiarise yourself with the work to be remounted\n",
      "Similarity:0.7932\n",
      "=========================\n",
      "sentence: Create & articulate compelling value proposition around Mobile Labs solutions\n",
      "ESCO skill:plan marketing strategy\n",
      "Similarity:0.7233\n",
      "=========================\n",
      "sentence: Work with Partners to extend reach & drive adoption\n",
      "ESCO skill:identify opportunities\n",
      "Similarity:0.7241\n",
      "=========================\n",
      "sentence: Experience building new territories from scratch\n",
      "ESCO skill:find your place within the architecture of the production\n",
      "Similarity:0.6899\n",
      "=========================\n",
      "sentence: Ability to learn complex systems and processes\n",
      "ESCO skill:use agricultural information systems and databases\n",
      "Similarity:0.7261\n",
      "=========================\n",
      "sentence: A flexible schedule that can accommodate the requirements of a salesperson in the field.\n",
      "ESCO skill:search for a suitable location\n",
      "Similarity:0.7589\n",
      "=========================\n",
      "sentence: Travel, quarter end etc.\n",
      "ESCO skill:control of expenses\n",
      "Similarity:0.7444\n",
      "=========================\n",
      "sentence: Understanding of the Software Development Life Cycle (SDLC), DevOps or Agile Development practices\n",
      "ESCO skill:Agile development\n",
      "Similarity:0.8232\n",
      "=========================\n",
      "sentence: Must have strong verbal and written communication skills.\n",
      "ESCO skill:apply technical communication skills\n",
      "Similarity:0.8219\n"
     ]
    }
   ],
   "source": [
    "sentences = get_sentences(job_sample)\n",
    "\n",
    "sim_start_time = time.time()\n",
    "sent_embs = []\n",
    "\n",
    "for sent in sentences:\n",
    "    x = tokenizer(sent, return_tensors='pt')\n",
    "    x = {k:v.to(device) for k, v in x.items()}\n",
    "    emb = model(x).detach().cpu()\n",
    "    sent_embs.append(emb.squeeze())\n",
    "idxs, sims = compute_similarity_mat(sent_embs, emb_label)\n",
    "# Calculate job description processing time\n",
    "sim_end_time = time.time()\n",
    "execution_time = sim_end_time - sim_start_time\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "\n",
    "for r in res:\n",
    "    print('=========================')\n",
    "    print(f\"sentence: {r[0]}\\nESCO skill:{r[1]}\\nSimilarity:{r[2]:.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75ad5459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifiers(mtype):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    if mtype == \"jobbert\":\n",
    "        token_skill_classifier = pipeline(model=\"jjzha/jobbert_skill_extraction\", aggregation_strategy=\"first\", device='cpu')\n",
    "        token_knowledge_classifier = pipeline(model=\"jjzha/jobbert_knowledge_extraction\", aggregation_strategy=\"first\", device=device)\n",
    "    elif mtype == \"xlmr\":        \n",
    "        token_skill_classifier = pipeline(model=\"jjzha/escoxlmr_skill_extraction\", aggregation_strategy=\"first\", device=device)\n",
    "        token_knowledge_classifier = pipeline(model=\"jjzha/escoxlmr_knowledge_extraction\", aggregation_strategy=\"first\", device=device)\n",
    "    else:\n",
    "        raise Exception(\"Unknown model name provided\")\n",
    "    return token_skill_classifier, token_knowledge_classifier\n",
    "\n",
    "\n",
    "def extract_skills(job, token_skill_classifier, token_knowledge_classifier, out_treshold=.8, sim_threshold=.8):\n",
    "    \"\"\"\n",
    "    Function that processes outputs from pre-trained, ready to use models\n",
    "    that detect skills as a token classification task. There are two thresholds,\n",
    "    out_threshold for filtering model outputs and sim_threshold for filtering\n",
    "    based on vector similarity with ESCO skills\n",
    "    \"\"\"     \n",
    "    sentences = get_sentences(job)\n",
    "    pred_labels = []\n",
    "    res = []\n",
    "    skill_embs = []\n",
    "    skill_texts = []\n",
    "    for sent in sentences:\n",
    "        skills = ner(sent, token_skill_classifier, token_knowledge_classifier)\n",
    "        for entity in skills['entities']:\n",
    "            text = entity['word']\n",
    "            if entity['score'] > out_treshold:\n",
    "                skill_embs.append(get_embedding(text).squeeze())\n",
    "                skill_texts.append(text)\n",
    "                \n",
    "    idxs, sims = compute_similarity_mat(skill_embs, emb_label)\n",
    "    for i in range(len(idxs)):\n",
    "        if sims[i] > sim_threshold:\n",
    "            pred_labels.append(idxs[i])\n",
    "            res.append((skill_texts[i], esco_df.iloc[idxs[i]]['label_cleaned'], sims[i]))\n",
    "    return pred_labels, res\n",
    "\n",
    "\n",
    "def aggregate_span(results):\n",
    "    new_results = []\n",
    "    current_result = results[0]\n",
    "\n",
    "    for result in results[1:]:\n",
    "        if result[\"start\"] == current_result[\"end\"] + 1:\n",
    "            current_result[\"word\"] += \" \" + result[\"word\"]\n",
    "            current_result[\"end\"] = result[\"end\"]\n",
    "        else:\n",
    "            new_results.append(current_result)\n",
    "            current_result = result\n",
    "\n",
    "    new_results.append(current_result)\n",
    "\n",
    "    return new_results\n",
    "\n",
    "\n",
    "def ner(text, token_skill_classifier, token_knowledge_classifier):\n",
    "    output_skills = token_skill_classifier(text)\n",
    "    for result in output_skills:\n",
    "        if result.get(\"entity_group\"):\n",
    "            result[\"entity\"] = \"Skill\"\n",
    "            del result[\"entity_group\"]\n",
    "\n",
    "    output_knowledge = token_knowledge_classifier(text)\n",
    "    for result in output_knowledge:\n",
    "        if result.get(\"entity_group\"):\n",
    "            result[\"entity\"] = \"Knowledge\"\n",
    "            del result[\"entity_group\"]\n",
    "\n",
    "    if len(output_skills) > 0:\n",
    "        output_skills = aggregate_span(output_skills)\n",
    "    if len(output_knowledge) > 0:\n",
    "        output_knowledge = aggregate_span(output_knowledge)\n",
    "    \n",
    "    skills = []\n",
    "    skills.extend(output_skills)\n",
    "    skills.extend(output_knowledge)\n",
    "    return {\"text\": text, \"entities\": skills}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20530981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c964be68a50746e2b5fbab01d418530a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tsc, tkc \u001b[38;5;241m=\u001b[39m \u001b[43mget_classifiers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjobbert\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      4\u001b[0m _, res \u001b[38;5;241m=\u001b[39m extract_skills(job_sample, tsc, tkc)\n",
      "Cell \u001b[0;32mIn[54], line 4\u001b[0m, in \u001b[0;36mget_classifiers\u001b[0;34m(mtype)\u001b[0m\n\u001b[1;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjobbert\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 4\u001b[0m     token_skill_classifier \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjjzha/jobbert_skill_extraction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggregation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfirst\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     token_knowledge_classifier \u001b[38;5;241m=\u001b[39m pipeline(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjjzha/jobbert_knowledge_extraction\u001b[39m\u001b[38;5;124m\"\u001b[39m, aggregation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxlmr\u001b[39m\u001b[38;5;124m\"\u001b[39m:        \n",
      "File \u001b[0;32m~/anaconda3/envs/skillexplore/lib/python3.10/site-packages/transformers/pipelines/__init__.py:651\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_extractor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    649\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_extractor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m feature_extractor\n\u001b[0;32m--> 651\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpipeline_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/skillexplore/lib/python3.10/site-packages/transformers/pipelines/token_classification.py:102\u001b[0m, in \u001b[0;36mTokenClassificationPipeline.__init__\u001b[0;34m(self, args_parser, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, args_parser\u001b[38;5;241m=\u001b[39mTokenClassificationArgumentHandler(), \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_model_type(\n\u001b[1;32m    104\u001b[0m         TF_MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING\n\u001b[1;32m    107\u001b[0m     )\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_basic_tokenizer \u001b[38;5;241m=\u001b[39m BasicTokenizer(do_lower_case\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/skillexplore/lib/python3.10/site-packages/transformers/pipelines/base.py:732\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[0;34m(self, model, tokenizer, feature_extractor, modelcard, framework, task, args_parser, device, binary_output, **kwargs)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodelcard \u001b[38;5;241m=\u001b[39m modelcard\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m=\u001b[39m framework\n\u001b[0;32m--> 732\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary_output \u001b[38;5;241m=\u001b[39m binary_output\n\u001b[1;32m    735\u001b[0m \u001b[38;5;66;03m# Special handling\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "tsc, tkc = get_classifiers(\"jobbert\")\n",
    "\n",
    "start_time = time.time()\n",
    "_, res = extract_skills(job_sample, tsc, tkc)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "for r in res:\n",
    "    print('=========================')\n",
    "    print(f\"text: {r[0]}\\nESCO skill:{r[1]}\\nSimilarity:{r[2]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
