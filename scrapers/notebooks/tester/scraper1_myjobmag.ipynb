{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T02:40:30.752777306Z",
     "start_time": "2023-10-19T02:40:30.728717078Z"
    }
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import TimeoutException as TS\n",
    "from selenium.webdriver.support import expected_conditions as conditions\n",
    "from selenium.webdriver.common.by import By\n",
    "import pickle as pk\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def url_builder(root_url, page_number):\n",
    "    url = f\"{root_url}/{page_number}\"\n",
    "    return url"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T02:40:30.753746192Z",
     "start_time": "2023-10-19T02:40:30.749306468Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T02:40:30.761162371Z",
     "start_time": "2023-10-19T02:40:30.756076995Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_links(driver, url):\n",
    "    driver.get(url)\n",
    "    \n",
    "    # wait for the page to load\n",
    "    # WebDriverWait(driver, 10)\n",
    "\n",
    "    links = []\n",
    "    x = 1  # Starting value of x\n",
    "    skip_counter = 0\n",
    "\n",
    "    while x < 24:\n",
    "        try:\n",
    "            # Construct the XPath for the div with the current x value\n",
    "            xpath = f\"//*[@id='cat-left-sec']/ul/li[{x}]/ul/li[2]/ul/li[1]/h2/a\"\n",
    "            \n",
    "            # try to get the element specified by the xpath, if it does not exist skip it\n",
    "            try:\n",
    "                WebDriverWait(driver, 1).until(\n",
    "                conditions.presence_of_element_located((By.XPATH, xpath))\n",
    "                )\n",
    "            except TS:\n",
    "                x += 1\n",
    "                skip_counter+=1\n",
    "                continue\n",
    "                \n",
    "                \n",
    "            element = driver.find_element(\"xpath\",xpath)\n",
    "            try:\n",
    "                # Find and store the first link within the div, if it exists\n",
    "                links.append(element.get_attribute(\"href\"))\n",
    "                                \n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "\n",
    "            x += 1  # Increment x for the next iteration\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            # When there are no more divs with the current x value, exit the loop\n",
    "            break\n",
    "\n",
    "    # Removing any duplicates and misleading links\n",
    "    # links = [link for link in links if \"listings\" in link]\n",
    "    # links = list(set(links))\n",
    "    \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def store_links(links):\n",
    "    filename = \"../links/myjobmag_links\"\n",
    "    \n",
    "    file = open(filename, \"wb\")\n",
    "    pk.dump(links, file)\n",
    "    file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T02:40:30.767624939Z",
     "start_time": "2023-10-19T02:40:30.760076946Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "url_builder() missing 1 required positional argument: 'page_number'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 30\u001B[0m\n\u001B[1;32m     26\u001B[0m     driver\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__exit__\u001B[39m()\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m---> 30\u001B[0m     main()\n",
      "Cell \u001B[0;32mIn[5], line 13\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Adding the paginated pages to the root url\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# done up to page 5 to limit the results to recent information only\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# starts from page 2 because page 1 is already accounted for in the initial list\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m10\u001B[39m):\n\u001B[0;32m---> 13\u001B[0m     urls\u001B[38;5;241m.\u001B[39mappend(url_builder(x))\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m url \u001B[38;5;129;01min\u001B[39;00m urls:\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFetching job links from \u001B[39m\u001B[38;5;132;01m{\u001B[39;00murl\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: url_builder() missing 1 required positional argument: 'page_number'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "    urls = [\n",
    "        \"https://www.myjobmag.co.ke/jobs-by-field/information-technology\",\n",
    "        \"https://www.myjobmag.co.ke/jobs-by-field/research-data-analysis\",\n",
    "    ]\n",
    "    links = []\n",
    "\n",
    "    driver = webdriver.Chrome(options = options)\n",
    "\n",
    "    # Adding the paginated pages to the root url\n",
    "    # done up to page 5 to limit the results to recent information only\n",
    "    # starts from page 2 because page 1 is already accounted for in the initial list\n",
    "    tac = time.perf_counter()\n",
    "\n",
    "    for root in urls[:2]:\n",
    "      for page_number in range(2, 10):\n",
    "        urls.append(url_builder(root, page_number))\n",
    "\n",
    "    for url in urls:\n",
    "      print(f\"Fetching job links from {url}\")\n",
    "      \n",
    "      # Check if page exists/returns a 404\n",
    "      response = requests.get(url)\n",
    "      if response.status_code == 404:\n",
    "        print(\"Link does not exist. Stopping...\")\n",
    "        break\n",
    "      else:\n",
    "        links.append(fetch_links(driver, url))\n",
    "    \n",
    "    tic = time.perf_counter()\n",
    "        \n",
    "    # flattening the lists into one dimension\n",
    "    links = [link for sublist in links for link in sublist]\n",
    "    store_links(links)\n",
    "    \n",
    "    \n",
    "    print(f\"Done. {len(links)} links have been fetched and pickledðŸ«™\")    \n",
    "    print(f\"Time Taken: {(tic - tac):.3f} seconds\")    \n",
    "    # Closes driver agent\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T02:40:32.228387973Z",
     "start_time": "2023-10-19T02:40:30.765206442Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
